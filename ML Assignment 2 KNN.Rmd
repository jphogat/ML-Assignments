---
title: "Assignment 2 K-NN"
author: "Jyoti Phogat"
date: "2022-10-06"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



###Project Background:

*Liability customers - Majority - Depositors

*Asset customers     - Small    - Borrowers

*Campaign of last year - conversion rate of 9.6% [Among the 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.]

*Goal : use k-NN to predict whether a new customer will accept a loan offer.

* Data (rows): 5000 customers

*Success class as 1 (loan acceptance)

####Packages used

```{r}
install.packages("psych")
library(psych)  #for creating dummies
install.packages("caret")
library(caret)  #for data partition, normalize data
install.packages("FNN")
library(FNN)    #for Perfoming knn classification
install.packages("class")
library(class)
install.packages("dplyr")
library(dplyr)
```


####Data Exploration

```{r}
#loading the data in R
originaldata <- read.csv("UniversalBank.csv")
```

```{r}
#Eliminating variables [id & zip code] from the dataset
df=subset(originaldata, select=-c(ID, ZIP.Code ))
```

```{r}
#creating dummies
#library(psych)
dummy_Education <- as.data.frame(dummy.code(df$Education))
names(dummy_Education) <- c("Education_1", "Education_2","Education_3") #renaming dummy variable
df_without_education <- subset(df, select=-c(Education)) #eliminating education variable

UBank_data <- cbind(df_without_education, dummy_Education) #main dataset

```

####Data Partition
```{r}
#Partitioning the data into Traning(60%) and Validation(40%)
#library(caret)
set.seed(2019)
Train_Index     = createDataPartition(UBank_data$Age, p= 0.6 , list=FALSE)
Train_Data      = UBank_data[Train_Index,]  #3001 observations

Validation_Data = UBank_data[-Train_Index,] #1999 observations
```

####Genearting Test Data
```{r}
Test_Data <- data.frame(Age=40 , Experience=10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities.Account = 0, CD.Account = 0, Online = 1,  CreditCard = 1, stringsAsFactors = FALSE)
```

####Data Normalization
```{r}
# Copy the original data
train.norm.df    <- Train_Data
valid.norm.df    <- Validation_Data
test.norm.df     <- Test_Data
maindata.norm.df <- UBank_data

head(maindata.norm.df)

# use preProcess() from the caret package to normalize .
norm.values <- preProcess(Train_Data[,-7], method=c("center", "scale"))

train.norm.df[,-7] <- predict(norm.values, Train_Data[,-7])  #Training Data
valid.norm.df [,-7]<- predict(norm.values, Validation_Data[,-7])#Validation Data
test.norm.df <- predict(norm.values, Test_Data)#Test Data
maindata.norm.df[,-7] <- predict(norm.values,UBank_data[,-7]) #Training + Validation data

head(maindata.norm.df)
```

####Perfoming k-NN classification , using k = 1
```{r}
#library(FNN)
set.seed(2019)
prediction <- knn(train = train.norm.df[,-7], test = valid.norm.df[,-7], 
          cl = train.norm.df[,7], k = 1, prob=TRUE) 
actual= valid.norm.df$Personal.Loan
prediction_prob = attr(prediction,"prob")



table(prediction,actual)  
mean(prediction==actual)  
```


```{r}
#library(class)
NROW(train.norm.df)
sqrt(3001)

```
####Generating loop to find best k
```{r}
#library(caret)
#library(FNN)

accuracy.df <- data.frame(k = seq(1, 60, 1), accuracy = rep(0, 60))

# compute knn for different k on validation.
for(i in 1:60) {
prediction <- knn(train = train.norm.df[,-7], test = valid.norm.df[-7], 
          cl = train.norm.df[,7], k = i, prob=TRUE) 

accuracy.df[i,2] <- mean(prediction==actual)


}
accuracy.df  

```
#####Answer 2: The value of k we choose is 3 as it provides the best result [i.e the choice of k that balances between overfitting and ignoring the predictor information]

####Validation data results using best k value [i.e: k = 3]
```{r}
#library(FNN)
set.seed(2019)
prediction <- knn(train = train.norm.df[,-7], test = valid.norm.df[,-7], 
          cl = train.norm.df[,7], k = 3, prob=TRUE) 
actual= valid.norm.df$Personal.Loan
prediction_prob = attr(prediction,"prob")



#Answer 3: confusion matrix for the best k value =3
table(prediction,actual)  

#accuracy of the best k=3
mean(prediction==actual)  
```

#### Classifying the customer using the best k  [perfominng k-NN classification on test data]
```{r}
#library(FNN)
prediction_test <- knn(train = maindata.norm.df[,-7], test = Test_Data, 
          cl = maindata.norm.df[,7], k = 1, prob=TRUE) 


head(prediction_test)

```
#####Answer 4: k-NN model predicted that the new customer will accept a loan offer [loan accepted]


####Question 5
```{r}
#Repartitiong the data 

#Partitioning the data into Traning(50%) ,Validation(30%), Test(20%)
#library(dplyr)
#library(caret)
set.seed(2019)

Test_Index_1 = createDataPartition(UBank_data$Age, p= 0.2 , list=FALSE) #20% test data 
Test_Data_1  = UBank_data [Test_Index_1,]

Rem_DATA = UBank_data[-Test_Index_1,] #80% remaining data [training + validation]

Train_Index_1 = createDataPartition(Rem_DATA$Age, p= 0.5 , list=FALSE)
Train_Data_1 = Rem_DATA[Train_Index_1,] #Training data

Validation_Data_1 = Rem_DATA[-Train_Index_1,] #Validation data

```


```{r}
#Data Normalization


# Copy the original data
train.norm.df_1 <- Train_Data_1
valid.norm.df_1 <- Validation_Data_1
test.norm.df_1 <- Test_Data_1
rem_data.norm.df_1 <- Rem_DATA

# use preProcess() from the caret package to normalize Sales and Age.
norm.values_1 <- preProcess(Train_Data_1[-7], method=c("center", "scale"))

train.norm.df_1[-7] <- predict(norm.values_1, Train_Data_1[-7])  #Training Data
valid.norm.df_1[-7] <- predict(norm.values_1, Validation_Data_1[-7])#Validation Data
test.norm.df_1[-7] <- predict(norm.values_1, test.norm.df_1[-7]) #Test Data
test.norm.df_1[-7] <- predict(norm.values_1, Test_Data_1[-7])
rem_data.norm.df_1[-7] <- predict(norm.values_1,Rem_DATA[-7]) #Training + Validation data

head(test.norm.df_1)
```


```{r}
#Perfoming k-NN classification on Training Data, k = 3


#library(FNN)
set.seed(2019)
prediction_Q5 <- knn(train = train.norm.df_1[,-7], test = valid.norm.df_1[,-7], 
          cl = train.norm.df_1[,7], k = 3, prob=TRUE) 
actual= valid.norm.df_1$Personal.Loan
prediction_prob = attr(prediction_Q5,"prob")

table(prediction_Q5,actual)  #confusion matrix for the best k value =3
mean(prediction_Q5==actual)  #accuracy of the best k=3
```
```{r}
#Perfoming k-NN classification on Test Data, k = 3


library(FNN)
set.seed(2019)
prediction_Q5 <- knn(train = rem_data.norm.df_1[,-7], test = test.norm.df_1[,-7], 
          cl = rem_data.norm.df_1[,7], k = 3, prob=TRUE) 
actual= test.norm.df_1$Personal.Loan
prediction_prob = attr(prediction_Q5,"prob")

table(prediction_Q5,actual)  #confusion matrix for the best k value =3
mean(prediction_Q5==actual)  #accuracy of the best k=3
```
#####The model performed better in the test set, as it got enough data to learn from i.e 80% of the data, Whereas when we were working on training data it only learned from 50% of the data.
